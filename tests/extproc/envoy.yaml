# Copyright Envoy AI Gateway Authors
# SPDX-License-Identifier: Apache-2.0
# The full text of the Apache license is available in the LICENSE file at
# the root of the repo.

admin:
  address:
    socket_address:
      address: 127.0.0.1
      port_value: 9901

static_resources:
  listeners:
    - address:
        socket_address:
          address: 0.0.0.0
          port_value: 1062
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: ingress_http
                codec_type: auto
                access_log:
                  - name: log_used_token
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
                      path: ACCESS_LOG_PATH
                      log_format:
                        json_format:
                          used_token: "%DYNAMIC_METADATA(ai_gateway_llm_ns:used_token)%"
                          some_cel: "%DYNAMIC_METADATA(ai_gateway_llm_ns:some_cel)%"
                          timestamp: "%START_TIME%"
                          protocol: "%PROTOCOL%"
                          method: "%REQ(:METHOD)%"
                          path: "%REQ(X-ENVOY-ORIGINAL-PATH?:PATH)%"
                          response_code: "%RESPONSE_CODE%"
                          response_code_detail: "%RESPONSE_CODE_DETAILS%"
                          response_flags: "%RESPONSE_FLAGS%"
                          bytes_received: "%BYTES_RECEIVED%"
                          bytes_sent: "%BYTES_SENT%"
                          duration: "%DURATION%"
                          x_forwarded_for: "%REQ(X-FORWARDED-FOR)%"
                          user_agent: "%REQ(USER-AGENT)%"
                          request_id: "%REQ(X-REQUEST-ID)%"
                          authority: "%REQ(:AUTHORITY)%"
                          upstream_host: "%UPSTREAM_HOST%"
                          upstream_host_name: "%UPSTREAM_HOST_NAME%"
                          requested_server_name: "%REQUESTED_SERVER_NAME%"
                          host_name: "%HOSTNAME%"
                          access_log_type: "%ACCESS_LOG_TYPE%"
                          filter_chain_name: "%FILTER_CHAIN_NAME%"
                          env_http_proxy: "%ENVIRONMENT(HTTP_PROXY)%"
                          env_https_proxy: "%ENVIRONMENT(HTTPS_PROXY)%"
                          env_proxy: "%ENVIRONMENT(PROXY)%"
                          upstream_protocol: "%UPSTREAM_PROTOCOL%"
                route_config:
                  virtual_hosts:
                    - name: local_route
                      domains:
                        - "*"
                      routes:
                        - match:
                            prefix: "/"
                            headers:
                              - name: x-selected-backend-name
                                string_match:
                                  exact: aws-bedrock
                          route:
                            host_rewrite_literal: bedrock-runtime.us-east-1.amazonaws.com
                            cluster: aws_bedrock
                        - match:
                            prefix: "/"
                            headers:
                              - name: x-selected-backend-name
                                string_match:
                                  exact: openai
                          route:
                            host_rewrite_literal: api.openai.com
                            cluster: openai
                        - match:
                            prefix: "/"
                            headers:
                              - name: x-selected-backend-name
                                string_match:
                                  exact: azure-openai
                          route:
                            host_rewrite_literal: <azure_resource_name>.openai.azure.com   # Replace with your azure resource name
                            cluster: azure_openai
                        - match:
                            prefix: "/"
                            headers:
                              - name: x-selected-backend-name
                                string_match:
                                  exact: testupstream
                          route:
                            cluster: testupstream
                        - match:
                            prefix: "/"
                            headers:
                              - name: x-selected-backend-name
                                string_match:
                                  exact: original_destination_cluster
                          name: original_destination_cluster
                          route:
                            cluster: original_destination_cluster
                http_filters:
                  - name: envoy.filters.http.ext_proc
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor
                      allow_mode_override: true
                      processing_mode:
                        request_header_mode: "SEND"
                        response_header_mode: "SEND"
                        request_body_mode: "BUFFERED"
                        response_body_mode: "BUFFERED"
                      grpc_service:
                        envoy_grpc:
                          cluster_name: extproc_cluster
                      metadataOptions:
                        receivingNamespaces:
                          untyped:
                            - ai_gateway_llm_ns
                  - name: envoy.filters.http.router
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
                      suppressEnvoyHeaders: true

  clusters:
    - name: testupstream
      connect_timeout: 0.25s
      type: STATIC
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: testupstream
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: 127.0.0.1
                      port_value: 8080
    - name: extproc_cluster
      connect_timeout: 0.25s
      type: STATIC
      lb_policy: ROUND_ROBIN
      typed_extension_protocol_options:
        envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
          "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
          explicit_http_config:
            http2_protocol_options:
              connection_keepalive:
                interval: 30s
                timeout: 5s
      load_assignment:
        cluster_name: extproc_cluster
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: 127.0.0.1
                      port_value: 1063
    - name: aws_bedrock
      connect_timeout: 30s
      type: STRICT_DNS
      load_assignment:
        cluster_name: aws_bedrock
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: bedrock-runtime.us-east-1.amazonaws.com
                      port_value: 443
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
          sni: bedrock-runtime.us-east-1.amazonaws.com
    - name: openai
      connect_timeout: 30s
      type: STRICT_DNS
      load_assignment:
        cluster_name: openai
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: api.openai.com
                      port_value: 443
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
          sni: api.openai.com
    - name: azure_openai
      connect_timeout: 30s
      type: STRICT_DNS
      load_assignment:
        cluster_name: azure_openai
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: <azure_resource_name>.openai.azure.com   # Replace with your azure resource name
                      port_value: 443
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
          sni: <azure_resource_name>.openai.azure.com   # Replace with your azure resource name
    - name: original_destination_cluster
      connectTimeout: 30s
      type: ORIGINAL_DST
      lbPolicy: CLUSTER_PROVIDED
      originalDstLbConfig:
        httpHeaderName: x-ai-eg-original-dst
        useHttpHeader: true

overload_manager:
  refresh_interval: 0.25s
  resource_monitors:
    - name: "envoy.resource_monitors.global_downstream_max_connections"
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.resource_monitors.downstream_connections.v3.DownstreamConnectionsConfig
        max_active_downstream_connections: 1000
