{
  "series": {
    "version": "v0.3",
    "title": "Envoy AI Gateway v0.3.x",
    "subtitle": "Release version introducing intelligent inference routing with Endpoint Picker Provider,enhanced observability features, Google Vertex AI support, and enhanced provider integrations.",
    "badge": "Stable",
    "badgeType": "milestone"
  },
  "releases": [
    {
      "version": "v0.3.0",
      "date": "August 21, 2025",
      "type": "minor",
      "tags": [
        { "text": "Endpoint Picker Support", "type": "feature" },
        { "text": "Google Vertex AI", "type": "feature" },
        { "text": "Expanded Provider Ecosystem", "type": "feature" },
        { "text": "Architecture Improvements", "type": "feature" },
        { "text": "InferencePool Support", "type": "feature" },
        { "text": "Gateway API Inference Extension", "type": "feature" },
        { "text": "OpenInference Tracing", "type": "feature" },
        { "text": "Model Name Virtualization", "type": "feature" },
        { "text": "Production Ready Providers", "type": "feature" },
        { "text": "Dynamic Load Balancing", "type": "feature" },
        { "text": "Configurable Metrics", "type": "feature" },
        { "text": "OpenInference Tracing", "type": "feature" }
      ],
      "overview": "Envoy AI Gateway v0.3.0 introduces intelligent inference routing, expanded provider support (including Google Vertex AI and Anthropic), and enhanced observability with OpenInference tracing and configurable metrics. Key features include Endpoint Picker Provider with InferencePool for dynamic load balancing, model name virtualization, and seamless Gateway API Inference Extension integration.",
      "features": [
        {
          "title": "Endpoint Picker Provider (EPP) Integration",
          "items": [
            {
              "title": "Gateway API Inference Extension Support",
              "description": "Complete integration with Gateway API Inference Extension v0.5.1, enabling intelligent endpoint selection based on real-time AI inference metrics like KV-cache usage, queue depth, and LoRA adapter information."
            },
            {
              "title": "Dual Integration Approaches",
              "description": "Support for both <code>HTTPRoute + InferencePool</code> and <code>AIGatewayRoute + InferencePool</code> integration patterns, providing flexibility for different use cases from simple to advanced AI routing scenarios."
            },
            {
              "title": "Dynamic Load Balancing",
              "description": "Intelligent routing that automatically selects the optimal inference endpoint for each request, optimizing resource utilization across your entire inference infrastructure with real-time performance metrics."
            },
            {
              "title": "Extensible Architecture",
              "description": "Support for custom endpoint picker providers, allowing implementation of domain-specific routing logic tailored to unique AI workload requirements."
            }
          ]
        },
        {
          "title": "Expanded Provider Ecosystem",
          "items": [
            {
              "title": "Google Vertex AI Production Support",
              "description": "Google Vertex AI has moved from work-in-progress to full production support, including complete streaming support for Gemini models with OpenAI API compatibility. <a href=\"/docs/capabilities/llm-integrations/supported-providers\">View all supported providers →</a>"
            },
            {
              "title": "Anthropic on Vertex AI Integration",
              "description": "Complete Anthropic Claude integration via GCP Vertex AI, moving from experimental to production-ready status with multi-tool support and configurable API versions for enterprise deployments."
            },
            {
              "title": "Enhanced Gemini Capabilities",
              "description": "Improved request/response translation for Gemini models with support for tools, response format specification, and advanced conversation handling, making Gemini integration more robust and feature-complete."
            },
            {
              "title": "Strengthened OpenAI-Compatible Ecosystem",
              "description": "Enhanced support for the broader OpenAI-compatible provider ecosystem including Groq, Together AI, Mistral, Cohere, DeepSeek, SambaNova, and more, ensuring seamless integration across the AI provider landscape."
            }
          ]
        },
        {
          "title": "Observability Enhancements",
          "items": [
            {
              "title": "OpenInference Tracing Support",
              "description": "Added comprehensive OpenInference distributed tracing with OpenTelemetry integration, providing detailed request tracing and performance monitoring for LLM operations. Includes full chat completion request/response data capture, timing information, and compatibility with evaluation systems like Arize Phoenix. <a href=\"/docs/capabilities/observability/tracing\">View the documentation →</a>"
            },
            {
              "title": "Configurable Metrics Labels",
              "description": "Added support for configuring additional metrics labels corresponding to HTTP request headers. This enables custom labeling of metrics based on specific request headers like user identifiers, API versions, or application contexts, providing more granular monitoring and filtering capabilities."
            },
            {
              "title": "Embeddings Metrics Support",
              "description": "Extended GenAI metrics support to include embeddings operations, providing comprehensive token usage tracking and performance monitoring for both chat completion and embeddings API endpoints with consistent OpenTelemetry semantic conventions."
            },
            {
              "title": "Enhanced GenAI Metrics",
              "description": "Improved AI-specific metrics implementation with better error handling, enhanced attribute mapping, and more accurate token latency measurements. Maintains full compatibility with OpenTelemetry Gen AI semantic conventions while providing more reliable performance analysis data. <a href=\"/docs/capabilities/observability/metrics\">View the documentation →</a>"
            }
          ]
        },
        {
          "title": "Infrastructure and Configuration",
          "items": [
            {
              "title": "Model Name Virtualization",
              "description": "Added a new <code>modelNameOverride</code> field in the <code>backendRef</code> of <code>AIGatewayRoute</code>, enabling flexible model name abstraction across different providers. This allows unified model naming for downstream applications while routing to provider-specific model names, supporting both multi-provider scenarios and fallback configurations. <a href=\"/docs/capabilities/traffic/model-name-virtualization\">View the documentation →</a>"
            },
            {
              "title": "Unified Gateway Support",
              "description": "Enhanced Gateway resource management by allowing both standard <code>HTTPRoute</code> and <code>AIGatewayRoute</code> to be attached to the same <code>Gateway</code> object. This provides a unified routing configuration that supports both AI and non-AI traffic within a single gateway infrastructure, simplifying deployment and management."
            }
          ]
        }
      ],
      "apiChanges": [
        {
          "title": "BackendSecurityPolicy TargetRefs",
          "description": "Added <code>targetRefs</code> field to BackendSecurityPolicy spec, enabling direct targeting of AIServiceBackend resources using Gateway API policy attachment patterns."
        },
        {
          "title": "Gateway API Inference Extension",
          "description": "Allows InferencePool resource of Gateway API Inference Extension v0.5.1 to be specified as a backend ref in AIGatewayRoute intelligent endpoint selection."
        },
        {
          "title": "modelNameOverride in the backend reference of AIGatewayRoute",
          "description": "Added <code>modelNameOverride</code> field in the backend reference of AIGatewayRoute, allowing for flexible model name rewrite for routing purposes."
        }
      ],
      "deprecations": [
        {
          "title": "<code>backendSecurityPolicyRef</code> Pattern",
          "description": "The old pattern of AIServiceBackend referencing BackendSecurityPolicy is deprecated in favor of the new targetRefs approach. Existing configurations will continue to work but should be migrated before v0.4."
        },
        {
          "title": "<code>AIGatewayRoute</code>'s <code>targetRefs</code> Pattern",
          "description": "The <code>targetRefs</code> pattern is no longer supported for <code>AIGatewayRoute</code>. Existing configurations will continue to work but should be migrated to <code>parentRefs</code>."
        },
        {
          "title": "<code>AIGatewayRoute</code>'s <code>schema</code> Field",
          "description": "The <code>schema</code> field is no longer needed for <code>AIGatewayRoute</code>. Existing configurations will continue to work but should be removed before v0.4."
        },
        {
          "title": "<code>controller.envoyGatewayNamespace</code> helm value is no longer necessary",
          "description": "This value is no longer necessary and is redundant when configured."
        },
        {
          "title": "<code>controller.podEnv</code> helm value will be removed",
          "description": "Use <code>controller.extraEnvVars</code> instead. The <code>controller.podEnv</code> value will be removed in v0.4."
        }
      ],
      "bugFixes": [],
      "dependencies": [
        { "title": "Go 1.24.6", "description": "Updated to latest Go version for improved performance and security." },
        { "title": "Envoy Gateway v1.5", "description": "Built on Envoy Gateway for proven data plane capabilities." },
        { "title": "Envoy v1.35", "description": "Leveraging Envoy Proxy's battle-tested networking capabilities." },
        { "title": "Gateway API v1.3.1", "description": "Support for latest Gateway API specifications." },
        { "title": "Gateway API Inference Extension v0.5.1", "description": "Integration with Gateway API Inference Extension for intelligent endpoint selection." }
      ]
    }
  ],
  "navigation": {
    "previous": { "version": "v0.2.x Series", "path": "/release-notes/v0.2" },
    "next": { "version": "v0.4.x Series", "path": "/release-notes/v0.4" }
  }
}
