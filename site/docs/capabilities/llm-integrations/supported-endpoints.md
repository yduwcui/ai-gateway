---
id: supported-endpoints
title: Supported API Endpoints
sidebar_position: 9
---

The Envoy AI Gateway provides OpenAI-compatible API endpoints as well as the Anthropic-compatible API for routing and managing LLM/AI traffic. This page documents which OpenAI API endpoints and Anthropic-compatible API endpoints are currently supported and their capabilities.

## Overview

The Envoy AI Gateway acts as a proxy that accepts OpenAI-compatible and Anthropic-compatible requests and routes them to various AI providers. While it maintains compatibility with the OpenAI API specification, it currently supports a subset of the full OpenAI API.

## Supported Endpoints

### Chat Completions

**Endpoint:** `POST /v1/chat/completions`

**Status:** âœ… Fully Supported

**Description:** Create a chat completion response for the given conversation.

**Features:**

- âœ… Streaming and non-streaming responses
- âœ… Function calling
- âœ… Response format specification (including JSON schema)
- âœ… Temperature, top_p, and other sampling parameters
- âœ… System and user messages
- âœ… Model selection via request body or `x-ai-eg-model` header
- âœ… Token usage tracking and cost calculation
- âœ… Provider fallback and load balancing

**Supported Providers:**

- OpenAI
- AWS Bedrock (with automatic translation)
- Azure OpenAI (with automatic translation)
- GCP VertexAI (with automatic translation)
- GCP Anthropic (with automatic translation)
- Any OpenAI-compatible provider (Groq, Together AI, Mistral, Tetrate Agent Router Service, etc.)

**Example:**

```bash
curl -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o-mini",
    "messages": [
      {
        "role": "user",
        "content": "Hello, how are you?"
      }
    ]
  }' \
  $GATEWAY_URL/v1/chat/completions
```

### Anthropic Messages

**Endpoint:** `POST /anthropic/v1/messages`

**Status:** âœ… Fully Supported

**Description:** Send a structured list of input messages with text and/or image content, and the model will generate the next message in the conversation.

**Features:**

- âœ… Streaming and non-streaming responses
- âœ… Function calling
- âœ… Extended thinking
- âœ… Response format specification (including JSON schema)
- âœ… Temperature, top_p, and other sampling parameters
- âœ… System and user messages
- âœ… Model selection via request body or `x-ai-eg-model` header
- âœ… Token usage tracking and cost calculation
- âœ… Provider fallback and load balancing

**Supported Providers:**

- Anthropic
- GCP Anthropic

**Example:**

```bash
curl -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4",
    "messages": [
      {
        "role": "user",
        "content": "Hello, how are you?"
      }
    ],
    "max_tokens": 100
  }' \
  $GATEWAY_URL/anthropic/v1/messages
```

### Completions

**Endpoint:** `POST /v1/completions`

**Status:** âœ… Fully Supported

**Description:** Create a text completion for the given prompt (legacy endpoint).

**Features:**

- âœ… Non-streaming responses
- âœ… Streaming responses
- âœ… Model selection via request body or `x-ai-eg-model` header
- âœ… Temperature, top_p, and other sampling parameters
- âœ… Single and batch prompt processing
- âœ… Token usage tracking and cost calculation
- âœ… Provider fallback and load balancing
- âœ… Full metrics support (token usage, request duration, time to first token, inter-token latency)

**Supported Providers:**

- OpenAI
- Any OpenAI-compatible provider that supports completions

**Example:**

```bash
curl -H "Content-Type: application/json" \
  -d '{
    "model": "babbage-002",
    "prompt": "def fib(n):\n    if n <= 1:\n        return n\n    else:\n        return fib(n-1) + fib(n-2)",
    "max_tokens": 25,
    "temperature": 0.4,
    "top_p": 0.9
  }' \
  $GATEWAY_URL/v1/completions
```

### Embeddings

**Endpoint:** `POST /v1/embeddings`

**Status:** âœ… Fully Supported

**Description:** Create embeddings for the given input text.

**Features:**

- âœ… Single and batch text embedding
- âœ… Model selection via request body or `x-ai-eg-model` header
- âœ… Token usage tracking and cost calculation
- âœ… Provider fallback and load balancing

**Supported Providers:**

- OpenAI
- Any OpenAI-compatible provider that supports embeddings, including Azure OpenAI.

### Image Generation

**Endpoint:** `POST /v1/images/generations`

**Status:** âœ… Supported

**Description:** Generate one or more images from a text prompt using OpenAI-compatible models.

**Features:**

- **Non-streaming responses**: Returns JSON payload with image URLs or base64 content
- **Model selection**: Via request body `model` or `x-ai-eg-model` header
- **Parameters**: `prompt`, `size`, `n`, `quality`, `response_format`
- **Metrics**: Records image count, model, and size; token usage when provided
- **Provider fallback and load balancing**

**Supported Providers:**

- OpenAI
- Any OpenAI-compatible provider that supports image generations

**Example:**

```bash
curl -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-image-1",
    "prompt": "a serene mountain landscape at sunrise in watercolor",
    "size": "1024x1024",
    "n": 1
  }' \
  $GATEWAY_URL/v1/images/generations
```

### Models

**Endpoint:** `GET /v1/models`

**Description:** List available models configured in the AI Gateway.

**Features:**

- âœ… Returns models declared in AIGatewayRoute configurations
- âœ… OpenAI-compatible response format
- âœ… Model metadata (ID, owned_by, created timestamp)

**Example:**

```bash
curl $GATEWAY_URL/v1/models
```

**Response Format:**

```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt-4o-mini",
      "object": "model",
      "created": 1677610602,
      "owned_by": "openai"
    }
  ]
}
```

## Provider-Endpoint Compatibility Table

The following table summarizes which providers support which endpoints:

| Provider                                                                                              | Chat Completions | Completions | Embeddings | Image Generation | Anthropic Messages | Notes                                                                                                                |
| ----------------------------------------------------------------------------------------------------- | :--------------: | :---------: | :--------: | :--------------: | :----------------: | -------------------------------------------------------------------------------------------------------------------- |
| [OpenAI](https://platform.openai.com/docs/api-reference)                                              |        âœ…        |     âœ…      |     âœ…     |        âœ…        |         âŒ         |                                                                                                                      |
| [AWS Bedrock](https://docs.aws.amazon.com/bedrock/latest/APIReference/)                               |        âœ…        |     ðŸš§      |     ðŸš§     |        âŒ        |         âŒ         | Via API translation                                                                                                  |
| [Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)                  |        âœ…        |     ðŸš§      |     âœ…     |        âš ï¸        |         âŒ         | Via API translation or via [OpenAI-compatible API](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/latest) |
| [Google Gemini](https://ai.google.dev/gemini-api/docs/openai)                                         |        âœ…        |     âš ï¸      |     âœ…     |        âš ï¸        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Groq](https://console.groq.com/docs/openai)                                                          |        âœ…        |     âŒ      |     âŒ     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Grok](https://docs.x.ai/docs/api-reference)                                                          |        âœ…        |     âš ï¸      |     âŒ     |        âš ï¸        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Together AI](https://docs.together.ai/docs/openai-api-compatibility)                                 |        âš ï¸        |     âš ï¸      |     âš ï¸     |        âš ï¸        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Cohere](https://docs.cohere.com/v2/docs/compatibility-api)                                           |        âš ï¸        |     âš ï¸      |     âš ï¸     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Mistral](https://docs.mistral.ai/api/)                                                               |        âš ï¸        |     âš ï¸      |     âš ï¸     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [DeepInfra](https://deepinfra.com/docs/inference)                                                     |        âœ…        |     âš ï¸      |     âœ…     |        âš ï¸        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [DeepSeek](https://api-docs.deepseek.com/)                                                            |        âš ï¸        |     âš ï¸      |     âŒ     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Hunyuan](https://cloud.tencent.com/document/product/1729/111007)                                     |        âš ï¸        |     âš ï¸      |     âš ï¸     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Tencent LLM Knowledge Engine](https://www.tencentcloud.com/document/product/1255/70381)              |        âš ï¸        |     âŒ      |     âŒ     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Tetrate Agent Router Service (TARS)](https://router.tetrate.ai/)                                     |        âš ï¸        |     âš ï¸      |     âš ï¸     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Google Vertex AI](https://cloud.google.com/vertex-ai/docs/reference/rest)                            |        âœ…        |     ðŸš§      |     ðŸš§     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Anthropic on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude) |        âœ…        |     âŒ      |     ðŸš§     |        âŒ        |         âœ…         | Via OpenAI-compatible API and Native Anthropic API                                                                   |
| [SambaNova](https://docs.sambanova.ai/sambastudio/latest/open-ai-api.html)                            |        âœ…        |     âš ï¸      |     âœ…     |        âŒ        |         âŒ         | Via OpenAI-compatible API                                                                                            |
| [Anthropic](https://docs.claude.com/en/home)                                                          |        âœ…        |     âŒ      |     âŒ     |        âŒ        |         âœ…         | Via OpenAI-compatible API and Native Anthropic API                                                                   |

- âœ… - Supported and Tested on Envoy AI Gateway CI
- âš ï¸ï¸ - Expected to work based on provider documentation, but not tested on the CI.
- âŒ - Not supported according to provider documentation.
- ðŸš§ - Unimplemented, or under active development but planned for future releases

## What's Next

To learn more about configuring and using the Envoy AI Gateway with these endpoints:

- **[Supported Providers](./supported-providers.md)** - Complete list of supported AI providers and their configurations
- **[Usage-Based Rate Limiting](../traffic/usage-based-ratelimiting.md)** - Configure token-based rate limiting and cost controls
- **[Provider Fallback](../traffic/provider-fallback.md)** - Set up automatic failover between providers for high availability
- **[Metrics and Monitoring](../observability/metrics.md)** - Monitor usage, costs, and performance metrics

[issue#609]: https://github.com/envoyproxy/ai-gateway/issues/609
