# Phoenix configuration - LLM-specific observability
# Phoenix uses port 6006 for OTLP
OTEL_EXPORTER_OTLP_ENDPOINT=http://phoenix:6006
OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
# Phoenix only supports traces, not metrics
OTEL_METRICS_EXPORTER=none
# Reduce trace export delay for demo purposes
OTEL_BSP_SCHEDULE_DELAY=100

# Below are default values for span redaction in OpenInference.
# See https://github.com/Arize-ai/openinference/blob/main/spec/configuration.md
OPENINFERENCE_HIDE_INPUTS=false
OPENINFERENCE_HIDE_OUTPUTS=false
# See https://github.com/Arize-ai/openinference/blob/main/spec/embedding_spans.md
OPENINFERENCE_HIDE_EMBEDDINGS_TEXT=false
OPENINFERENCE_HIDE_EMBEDDINGS_VECTORS=false
